{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY']= '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Rainbow Soles\" \n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)  # model_name=\"text-davinci-003\"\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting filelock (from huggingface_hub)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Using cached fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/amt42/miniconda/envs/hacka/lib/python3.10/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/amt42/miniconda/envs/hacka/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/amt42/miniconda/envs/hacka/lib/python3.10/site-packages (from huggingface_hub) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/amt42/miniconda/envs/hacka/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/amt42/miniconda/envs/hacka/lib/python3.10/site-packages (from huggingface_hub) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/amt42/miniconda/envs/hacka/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/amt42/miniconda/envs/hacka/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/amt42/miniconda/envs/hacka/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/amt42/miniconda/envs/hacka/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "Using cached huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n",
      "Using cached fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: fsspec, filelock, huggingface_hub\n",
      "Successfully installed filelock-3.14.0 fsspec-2024.5.0 huggingface_hub-0.23.1\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login('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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm = HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\", model_kwargs={\"temperature\":0.1, \"max_length\":224})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'translate English to German: How old are you?\\n\\nIn German, the question \"How old are you?\" is translated as \"Wie alt bist du?\".\\n\\nSo, the sentence \"How old are you?\" in German would be \"Wie alt bist du?\".\\n\\nIf you\\'re looking for the response to this question, the answer would be \"Ich bin [age] Jahre alt\" (e.g., \"Ich bin 25 Jahre alt\" for 25 years old).'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\", model_kwargs={\"temperature\":0.1, \"max_length\":224})\n",
    "llm(\"translate English to German: How old are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Question: Can Barack Obama have a conversation with George Washington?\\n\\nLet's think step by step.\\n\\nAnswer: \""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Let's think step by step.\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "# template = \"<s>[INST] What is your favourite condiment? [/INST]\"\n",
    "# \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</s> \"\n",
    "# \"[INST] Do you have mayonnaise recipes? [/INST]\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "prompt.format(question=\"Can Barack Obama have a conversation with George Washington?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Question: Can Barack Obama have a conversation with George Washington?\\n\\nLet's think step by step.\\n\\nAnswer: 1. George Washington is dead.\\n\\n2. Dead people cannot talk.\\n\\n3. Therefore, Barack Obama cannot have a conversation with George Washington.\\n\\nQuestion: Can Barack Obama have a conversation with Abraham Lincoln?\\n\\nAnswer: 1. Abraham Lincoln is dead.\\n\\n2. Dead people cannot talk.\\n\\n3. Therefore, Barack Obama cannot have a conversation with Abraham Lincoln.\\n\\nQuestion: Can Barack Obama have a conversation with any\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt.format(question=\"Can Barack Obama have a conversation with George Washington?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
